experiment:
  project: cross_view_transformers_test
  uuid: ${now:%m%d_%H%M%S}
  save_dir: ${hydra:runtime.cwd}/logs/
  seed: 2022
  checkpoint_interval: 1000
  log_image_interval: 500
  ckptt: '-'
loader:
  batch_size: 1
  num_workers: 1
  pin_memory: true
  prefetch_factor: 1
optimizer:
  weight_decay: 1.0e-07
scheduler:
  div_factor: 10
  pct_start: 0.3
  final_div_factor: 10
  max_lr: ${optimizer.lr}
  total_steps: ${trainer.max_steps}
  cycle_momentum: false
trainer:
  max_steps: 30001
  log_every_n_steps: 50
  gpus: -1
  precision: 32
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  check_val_every_n_epoch: 1
  val_check_interval: 1.0
  num_sanity_val_steps: 0
  gradient_clip_val: 5.0
  sync_batchnorm: false
model:
  _target_: transformer.cross_view_transformer.model.cvt.CrossViewTransformer
  level: 3
  decoder_block_channels: ${model.decoder.blocks}
  dim_last: 64
  bev_h: ${model.encoder.bev_embedding.bev_height}
  outputs:
    bev:
    - 0
    - 256
  encoder:
    _target_: transformer.cross_view_transformer.model.geometry_kernel_transformer_encoder_nuscenes.GeometryKernelEncoder
    dim: 128
    scale: 1.0
    middle:
    - 2
    - 2
    backbone:
      _target_: transformer.cross_view_transformer.model.backbones.efficientnet.EfficientNetExtractor
      model_name: efficientnet-b4
      layer_names:
      - reduction_2
      - reduction_4
      image_height: ${data.image.h}
      image_width: ${data.image.w}
    cross_view:
      heads: 4
      dim_head: 32
      qkv_bias: true
      skip: true
      no_image_features: false
      image_height: ${data.image.h}
      image_width: ${data.image.w}
      bev_z: 1.0
      kernel_h: 7
      kernel_w: 1
      sampling_type: index
      use_kernel_conv: true
      kernel_conv_h: 1
      kernel_conv_w: 7
    bev_embedding:
      sigma: 1.0
      bev_height: ${data.bev.h}
      bev_width: ${data.bev.w}
      h_meters: ${data.bev.h_meters}
      w_meters: ${data.bev.w_meters}
      offset: ${data.bev.offset}
      decoder_blocks: ${model.decoder.blocks}
  decoder:
    _target_: transformer.cross_view_transformer.model.decoder.Decoder
    dim: ${model.encoder.dim}
    blocks:
    - 256
    - 128
    - 64
    residual: true
    factor: 2
satellite_model:
  _target_: transformer.cross_view_transformer.model.cvt_satellite.CrossViewTransformer
  level: 3
  decoder_block_channels: ${model.decoder.blocks}
  dim_last: 64
  bev_h: ${model.encoder.bev_embedding.bev_height}
  outputs:
    bev:
    - 0
    - 10
  encoder:
    _target_: transformer.cross_view_transformer.model.encoder_satellite_nuscenes.Encoder
    dim: 128
    scale: 1.0
    middle:
    - 2
    - 2
    backbone:
      _target_: transformer.cross_view_transformer.model.backbones.efficientnet.EfficientNetExtractor
      model_name: efficientnet-b4
      layer_names:
      - reduction_2
      - reduction_4
      image_height: ${data.satellite_image.h}
      image_width: ${data.satellite_image.w}
    cross_view:
      heads: 4
      dim_head: 32
      qkv_bias: true
      skip: true
      no_image_features: false
      image_height: ${data.image.h}
      image_width: ${data.image.w}
    bev_embedding:
      sigma: 1.0
      bev_height: ${data.bev.h}
      bev_width: ${data.bev.w}
      h_meters: ${data.bev.h_meters}
      w_meters: ${data.bev.w_meters}
      offset: ${data.bev.offset}
      decoder_blocks: ${model.decoder.blocks}
  decoder:
    _target_: transformer.cross_view_transformer.model.decoder.Decoder
    dim: ${model.encoder.dim}
    blocks:
    - 256
    - 128
    - 64
    residual: true
    factor: 2
data:
  dataset: nuscenes_generated
  num_classes: 12
  version: v1.0-mini
  cameras:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  label_indices:
  - - 4
    - 5
    - 6
    - 7
    - 8
    - 10
    - 11
  bev:
    h: 256
    w: 256
    h_meters: 100.0
    w_meters: 100.0
    offset: 0.0
  augment: none
  image:
    h: 224
    w: 480
    top_crop: 46
  satellite_image:
    h: 1280
    w: 1280
  zoom_level: 18
visualization:
  _target_: transformer.cross_view_transformer.visualizations.nuscenes_viz.NuScenesViz
  label_indices: ${data.label_indices}
loss:
  bce_weight: 0.0
  bce:
    _target_: transformer.cross_view_transformer.losses.BinarySegmentationLoss
    label_indices: ${data.label_indices}
    gamma: 0.0
    alpha: -1.0
  focal_weight: 1.0
  focal:
    _target_: transformer.cross_view_transformer.losses.BinarySegmentationLoss
    label_indices: ${data.label_indices}
    gamma: 2.0
    alpha: -1.0
metrics:
  iou:
    _target_: transformer.cross_view_transformer.metrics.IoUMetric
    label_indices: ${data.label_indices}
highlyaccurate:
  date: '0409'
  resume: 0
  test: 0
  localize: 0
  debug: 0
  epochs: 500
  lr: 0.0001
  stereo: 0
  sequence: 1
  direction: S2GP
  rotation_range: 10.0
  shift_range_lat: 20.0
  shift_range_lon: 20.0
  level: -1
  N_iters: 5
  Load: 0
  coe_shift_lat: 100.0
  coe_shift_lon: 100.0
  coe_heading: 100.0
  coe_L1: 100.0
  coe_L2: 100.0
  coe_L3: 100.0
  coe_L4: 100.0
  metric_distance: 5.0
  loss_method: 0
  using_weight: 0
  damping: 0.1
  train_damping: 0
  negative_samples: 32
  use_conf_metric: 0
  Optimizer: LM
  level_first: 0
  proj: geo
  use_gt_depth: 0
  dropout: 0
  use_hessian: 0
  visualize: 0
  beta1: 0.9
  beta2: 0.999
  use_default_model: 0
  use_transformer: true
  version: ${data.version}
  labels_dir: /home/goroyeh/nuScene_dataset/media/datasets/cvt_labels_nuscenes
  dataset_dir: /mnt/workspace/datasets/nuScene_dataset/media/datasets/nuscenes
  root_dir: /mnt/workspace/datasets/nuScene_dataset/
  GrdImg_H: ${data.image.h}
  GrdImg_W: ${data.image.w}
  zoom_level: ${data.zoom_level}
  loader: ${loader}
